{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flight Price Model",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramanshsharma2806/Flight-Price/blob/master/Flight_Price_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sP5Lthf74U1",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Flight Price\n",
        "\n",
        "---\n",
        "\n",
        "This model will predict flight prices based on [this](https://www.kaggle.com/zernach/2018-airplane-flights) data.\n",
        "\n",
        "This model is being made for [mia](http://miamarketplace.com/), a place for people to run machine learning models interactively on the web."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ij-gFA8C4H_",
        "colab_type": "code",
        "outputId": "37955049-57ab-4979-d5b8-4ea59a2bc94e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "cellView": "form"
      },
      "source": [
        "#@title Require libraries import cell\n",
        "\"\"\"\n",
        "required libraries imported\n",
        "\"\"\"\n",
        "\n",
        "! pip install category_encoders\n",
        "import category_encoders as ce\n",
        "\n",
        "from __future__ import print_function\n",
        "import os, io, sys, random, time, pprint\n",
        "import numpy as np\n",
        "from numpy import save, load\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import one_hot\n",
        "from tensorflow.keras.callbacks import LambdaCallback, Callback, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import Model, Sequential\n",
        "from tensorflow.keras import backend\n",
        "from tensorflow.keras.layers import Activation, Reshape, Dense, Embedding, Dropout, Input, LayerNormalization, BatchNormalization, concatenate, Flatten, Concatenate\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD, Adadelta, Adagrad, Adamax\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# SOME CONSTANTS\n",
        "checkpoint_dir = '/content/drive/My Drive/MIA/best_model.hdf5'\n",
        "model_preds_train = '/content/drive/My Drive/MIA/train_preds.npy'\n",
        "model_preds_test = '/content/drive/My Drive/MIA/test_preds.npy'\n",
        "truth_train = '/content/drive/My Drive/MIA/truth_train.npy'\n",
        "truth_test = '/content/drive/My Drive/MIA/truth_test.npy'\n",
        "train_continuous_dir = '/content/drive/My Drive/MIA/train_continuous_dir.npy'\n",
        "test_continuous_dir = '/content/drive/My Drive/MIA/test_continuous_dir.npy'\n",
        "train_categorical_dir = '/content/drive/My Drive/MIA/train_categorical_dir.npy'\n",
        "test_categorical_dir = '/content/drive/My Drive/MIA/test_categorical_dir.npy'"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.6/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.0.4)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.18.4)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.15.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5.1->category_encoders) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fD0xB_VYOf30",
        "colab_type": "code",
        "outputId": "b5bc0b20-1d73-43ef-f1b8-565e0fcc509b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "\"\"\"\n",
        "testing if connected to TPU and/or GPU\n",
        "\"\"\"\n",
        "\n",
        "if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "  print('Not connected to a TPU runtime.')\n",
        "else:\n",
        "  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  print ('Connected to TPU.\\n\\nTPU address is', tpu_address)\n",
        "\n",
        "  with tf.compat.v1.Session((tpu_address)) as session:\n",
        "    devices = session.list_devices()\n",
        "    \n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(devices)\n",
        "\n",
        "if tf.test.gpu_device_name() == '':\n",
        "  print('\\n\\nNot connected to a GPU runtime.')\n",
        "else:\n",
        "  print('\\n\\nConnected to GPU: ' + tf.test.gpu_device_name())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Connected to TPU.\n",
            "\n",
            "TPU address is grpc://10.25.127.218:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, -7089418628287220199),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -773668112910610293),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 4570317225030166048),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -2060661325967762302),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -5441496292280368536),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -6525287944343962618),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 7963742658216293599),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 3484535094261132505),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, -4801152910968028220),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8349566322370067802),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 1728064394970357399)]\n",
            "\n",
            "\n",
            "Not connected to a GPU runtime.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4VLed2kKInb",
        "colab_type": "code",
        "outputId": "3ae9bfbf-5f7f-4d51-ea39-e5870387ff7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"\n",
        "need to mount the drive to access the data\n",
        "\"\"\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxPnoGubOh-S",
        "colab_type": "text"
      },
      "source": [
        "# Assumptions about the data\n",
        "\n",
        "\n",
        "\n",
        "## 1.   ItinID and MktID are ambiguous columns that do not seem to be significant towards predicting the flight price. The order in which the tickets are bought should not, in an obvious manner, affect how much an airline will charge for a flight. ticket. Ergo, these columns will be deleted.\n",
        "## 2. The OriginWac and DestWac columns are useless too. They are just arbirary US State/Territory World Area Code that will not affect the flight price. They shall be removed.\n",
        "## 3.   Several columns are categorical. In order to deal with categorical and contnuous data at the same time, we will use [this](https://datascience.stackexchange.com/questions/29634/how-to-combine-categorical-and-continuous-input-features-for-neural-network-trai) technique. The categorical inputs will be run through an Embedding layer and a small neural network, and then their outputs will be concantenated as inputs with the continuous data.\n",
        "\n",
        "## 4. The categorical data columns are: Origin, Dest, and AirlineCompany.\n",
        "\n",
        "## 5. ContiguousUSA is already a numerical variable with the values being [2, 1]. It does not need to be converted to numerical values, instead just needs to be normalized.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gq6kU9jy92xt",
        "colab_type": "code",
        "outputId": "f2dbb412-1950-4933-f919-8bbe651c7220",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        }
      },
      "source": [
        "\"\"\"\n",
        "reading data\n",
        "\"\"\"\n",
        "\n",
        "path = \"/content/drive/My Drive/MIA/Cleaned_2018_Flights.csv\"\n",
        "\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "df"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ItinID</th>\n",
              "      <th>MktID</th>\n",
              "      <th>MktCoupons</th>\n",
              "      <th>Quarter</th>\n",
              "      <th>Origin</th>\n",
              "      <th>OriginWac</th>\n",
              "      <th>Dest</th>\n",
              "      <th>DestWac</th>\n",
              "      <th>Miles</th>\n",
              "      <th>ContiguousUSA</th>\n",
              "      <th>NumTicketsOrdered</th>\n",
              "      <th>AirlineCompany</th>\n",
              "      <th>PricePerTicket</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>20181767585</td>\n",
              "      <td>2018176758501</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>PHL</td>\n",
              "      <td>23</td>\n",
              "      <td>LAX</td>\n",
              "      <td>91</td>\n",
              "      <td>2402.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>AA</td>\n",
              "      <td>672.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>20181767586</td>\n",
              "      <td>2018176758601</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>PHL</td>\n",
              "      <td>23</td>\n",
              "      <td>LAX</td>\n",
              "      <td>91</td>\n",
              "      <td>2402.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>AA</td>\n",
              "      <td>367.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>20181767587</td>\n",
              "      <td>2018176758701</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>PHL</td>\n",
              "      <td>23</td>\n",
              "      <td>LAX</td>\n",
              "      <td>91</td>\n",
              "      <td>2402.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>AA</td>\n",
              "      <td>417.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>20181767636</td>\n",
              "      <td>2018176763601</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>PHL</td>\n",
              "      <td>23</td>\n",
              "      <td>LAX</td>\n",
              "      <td>91</td>\n",
              "      <td>2402.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>AA</td>\n",
              "      <td>247.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>20181767637</td>\n",
              "      <td>2018176763701</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>PHL</td>\n",
              "      <td>23</td>\n",
              "      <td>LAX</td>\n",
              "      <td>91</td>\n",
              "      <td>2402.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>AA</td>\n",
              "      <td>276.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9534412</th>\n",
              "      <td>9534412</td>\n",
              "      <td>201844999082</td>\n",
              "      <td>20184499908202</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>STL</td>\n",
              "      <td>64</td>\n",
              "      <td>AUS</td>\n",
              "      <td>74</td>\n",
              "      <td>721.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>WN</td>\n",
              "      <td>310.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9534413</th>\n",
              "      <td>9534413</td>\n",
              "      <td>201844999092</td>\n",
              "      <td>20184499909203</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>BNA</td>\n",
              "      <td>54</td>\n",
              "      <td>MCI</td>\n",
              "      <td>64</td>\n",
              "      <td>491.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>WN</td>\n",
              "      <td>106.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9534414</th>\n",
              "      <td>9534414</td>\n",
              "      <td>201844999112</td>\n",
              "      <td>20184499911203</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>BOS</td>\n",
              "      <td>13</td>\n",
              "      <td>LIT</td>\n",
              "      <td>71</td>\n",
              "      <td>1260.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>WN</td>\n",
              "      <td>161.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9534415</th>\n",
              "      <td>9534415</td>\n",
              "      <td>201844999113</td>\n",
              "      <td>20184499911303</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>BOS</td>\n",
              "      <td>13</td>\n",
              "      <td>LIT</td>\n",
              "      <td>71</td>\n",
              "      <td>1260.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>WN</td>\n",
              "      <td>170.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9534416</th>\n",
              "      <td>9534416</td>\n",
              "      <td>201844999114</td>\n",
              "      <td>20184499911403</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>BOS</td>\n",
              "      <td>13</td>\n",
              "      <td>LIT</td>\n",
              "      <td>71</td>\n",
              "      <td>1260.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>WN</td>\n",
              "      <td>379.02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9534417 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Unnamed: 0        ItinID  ...  AirlineCompany  PricePerTicket\n",
              "0                 0   20181767585  ...              AA          672.87\n",
              "1                 1   20181767586  ...              AA          367.68\n",
              "2                 2   20181767587  ...              AA          417.94\n",
              "3                 3   20181767636  ...              AA          247.10\n",
              "4                 4   20181767637  ...              AA          276.35\n",
              "...             ...           ...  ...             ...             ...\n",
              "9534412     9534412  201844999082  ...              WN          310.10\n",
              "9534413     9534413  201844999092  ...              WN          106.17\n",
              "9534414     9534414  201844999112  ...              WN          161.19\n",
              "9534415     9534415  201844999113  ...              WN          170.87\n",
              "9534416     9534416  201844999114  ...              WN          379.02\n",
              "\n",
              "[9534417 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usWKXticolEl",
        "colab_type": "code",
        "outputId": "6c94ec64-08ea-40a0-c9d2-2cf13db0ac99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        }
      },
      "source": [
        "\"\"\"\n",
        "scaling the target Y price values\n",
        "\"\"\"\n",
        "\n",
        "bool_scale = False\n",
        "\n",
        "if bool_scale:\n",
        "  df['PricePerTicket'] = df['PricePerTicket'] / 1000.0 # scaling the target\n",
        "\n",
        "df"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ItinID</th>\n",
              "      <th>MktID</th>\n",
              "      <th>MktCoupons</th>\n",
              "      <th>Quarter</th>\n",
              "      <th>Origin</th>\n",
              "      <th>OriginWac</th>\n",
              "      <th>Dest</th>\n",
              "      <th>DestWac</th>\n",
              "      <th>Miles</th>\n",
              "      <th>ContiguousUSA</th>\n",
              "      <th>NumTicketsOrdered</th>\n",
              "      <th>AirlineCompany</th>\n",
              "      <th>PricePerTicket</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>20181767585</td>\n",
              "      <td>2018176758501</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>PHL</td>\n",
              "      <td>23</td>\n",
              "      <td>LAX</td>\n",
              "      <td>91</td>\n",
              "      <td>2402.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>AA</td>\n",
              "      <td>672.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>20181767586</td>\n",
              "      <td>2018176758601</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>PHL</td>\n",
              "      <td>23</td>\n",
              "      <td>LAX</td>\n",
              "      <td>91</td>\n",
              "      <td>2402.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>AA</td>\n",
              "      <td>367.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>20181767587</td>\n",
              "      <td>2018176758701</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>PHL</td>\n",
              "      <td>23</td>\n",
              "      <td>LAX</td>\n",
              "      <td>91</td>\n",
              "      <td>2402.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>AA</td>\n",
              "      <td>417.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>20181767636</td>\n",
              "      <td>2018176763601</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>PHL</td>\n",
              "      <td>23</td>\n",
              "      <td>LAX</td>\n",
              "      <td>91</td>\n",
              "      <td>2402.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>AA</td>\n",
              "      <td>247.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>20181767637</td>\n",
              "      <td>2018176763701</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>PHL</td>\n",
              "      <td>23</td>\n",
              "      <td>LAX</td>\n",
              "      <td>91</td>\n",
              "      <td>2402.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>AA</td>\n",
              "      <td>276.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9534412</th>\n",
              "      <td>9534412</td>\n",
              "      <td>201844999082</td>\n",
              "      <td>20184499908202</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>STL</td>\n",
              "      <td>64</td>\n",
              "      <td>AUS</td>\n",
              "      <td>74</td>\n",
              "      <td>721.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>WN</td>\n",
              "      <td>310.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9534413</th>\n",
              "      <td>9534413</td>\n",
              "      <td>201844999092</td>\n",
              "      <td>20184499909203</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>BNA</td>\n",
              "      <td>54</td>\n",
              "      <td>MCI</td>\n",
              "      <td>64</td>\n",
              "      <td>491.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>WN</td>\n",
              "      <td>106.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9534414</th>\n",
              "      <td>9534414</td>\n",
              "      <td>201844999112</td>\n",
              "      <td>20184499911203</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>BOS</td>\n",
              "      <td>13</td>\n",
              "      <td>LIT</td>\n",
              "      <td>71</td>\n",
              "      <td>1260.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>WN</td>\n",
              "      <td>161.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9534415</th>\n",
              "      <td>9534415</td>\n",
              "      <td>201844999113</td>\n",
              "      <td>20184499911303</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>BOS</td>\n",
              "      <td>13</td>\n",
              "      <td>LIT</td>\n",
              "      <td>71</td>\n",
              "      <td>1260.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>WN</td>\n",
              "      <td>170.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9534416</th>\n",
              "      <td>9534416</td>\n",
              "      <td>201844999114</td>\n",
              "      <td>20184499911403</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>BOS</td>\n",
              "      <td>13</td>\n",
              "      <td>LIT</td>\n",
              "      <td>71</td>\n",
              "      <td>1260.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>WN</td>\n",
              "      <td>379.02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9534417 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Unnamed: 0        ItinID  ...  AirlineCompany  PricePerTicket\n",
              "0                 0   20181767585  ...              AA          672.87\n",
              "1                 1   20181767586  ...              AA          367.68\n",
              "2                 2   20181767587  ...              AA          417.94\n",
              "3                 3   20181767636  ...              AA          247.10\n",
              "4                 4   20181767637  ...              AA          276.35\n",
              "...             ...           ...  ...             ...             ...\n",
              "9534412     9534412  201844999082  ...              WN          310.10\n",
              "9534413     9534413  201844999092  ...              WN          106.17\n",
              "9534414     9534414  201844999112  ...              WN          161.19\n",
              "9534415     9534415  201844999113  ...              WN          170.87\n",
              "9534416     9534416  201844999114  ...              WN          379.02\n",
              "\n",
              "[9534417 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtgUyuabSD9M",
        "colab_type": "code",
        "outputId": "e9e4e65f-ec9e-4d8f-c544-c672a2e0cd5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "\"\"\"\n",
        "removing the first three unnecessary columns\n",
        "removing OriginWac and DestWac because they are useless\n",
        "\"\"\"\n",
        "\n",
        "df.drop(['Unnamed: 0', 'ItinID', 'MktID', 'OriginWac', 'DestWac'], axis=1, inplace=True) # dropping index_col, ItinID, and MktID, OriginWac, DestWac\n",
        "\n",
        "df"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MktCoupons</th>\n",
              "      <th>Quarter</th>\n",
              "      <th>Origin</th>\n",
              "      <th>Dest</th>\n",
              "      <th>Miles</th>\n",
              "      <th>ContiguousUSA</th>\n",
              "      <th>NumTicketsOrdered</th>\n",
              "      <th>AirlineCompany</th>\n",
              "      <th>PricePerTicket</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>PHL</td>\n",
              "      <td>LAX</td>\n",
              "      <td>2402.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>AA</td>\n",
              "      <td>672.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>PHL</td>\n",
              "      <td>LAX</td>\n",
              "      <td>2402.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>AA</td>\n",
              "      <td>367.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>PHL</td>\n",
              "      <td>LAX</td>\n",
              "      <td>2402.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>AA</td>\n",
              "      <td>417.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>PHL</td>\n",
              "      <td>LAX</td>\n",
              "      <td>2402.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>AA</td>\n",
              "      <td>247.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>PHL</td>\n",
              "      <td>LAX</td>\n",
              "      <td>2402.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>AA</td>\n",
              "      <td>276.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9534412</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>STL</td>\n",
              "      <td>AUS</td>\n",
              "      <td>721.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>WN</td>\n",
              "      <td>310.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9534413</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>BNA</td>\n",
              "      <td>MCI</td>\n",
              "      <td>491.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>WN</td>\n",
              "      <td>106.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9534414</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>BOS</td>\n",
              "      <td>LIT</td>\n",
              "      <td>1260.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>WN</td>\n",
              "      <td>161.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9534415</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>BOS</td>\n",
              "      <td>LIT</td>\n",
              "      <td>1260.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>WN</td>\n",
              "      <td>170.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9534416</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>BOS</td>\n",
              "      <td>LIT</td>\n",
              "      <td>1260.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>WN</td>\n",
              "      <td>379.02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9534417 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         MktCoupons  Quarter  ... AirlineCompany PricePerTicket\n",
              "0                 1        1  ...             AA         672.87\n",
              "1                 1        1  ...             AA         367.68\n",
              "2                 1        1  ...             AA         417.94\n",
              "3                 1        1  ...             AA         247.10\n",
              "4                 1        1  ...             AA         276.35\n",
              "...             ...      ...  ...            ...            ...\n",
              "9534412           1        4  ...             WN         310.10\n",
              "9534413           1        4  ...             WN         106.17\n",
              "9534414           1        4  ...             WN         161.19\n",
              "9534415           1        4  ...             WN         170.87\n",
              "9534416           1        4  ...             WN         379.02\n",
              "\n",
              "[9534417 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vEVPeqZK1Nx",
        "colab_type": "text"
      },
      "source": [
        "## Applying the different types of encodings for all the variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDwAFyRLKuMK",
        "colab_type": "code",
        "outputId": "40de2c3e-0eff-4b2a-ef4d-a9a67cafb8cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "\"\"\"\n",
        "different types of encodings for all the variables\n",
        "Miles, NumTicketsOrdered: continuous, no encoding\n",
        "MktCoupons, ContiguousUSA: one hot encoding\n",
        "Quarter: ordinal encoding (doesn't need to be applied, the variable is already numerically ordinal)\n",
        "Origin, Dest, AirlineCompany: mean/target encoding\n",
        "******************THIS IS NOT DONE RIGHT NOW******************\n",
        "\"\"\"\n",
        "\n",
        "# making the target variable the last one\n",
        "temp_col = df['PricePerTicket']\n",
        "df.drop('PricePerTicket', axis=1, inplace=True)\n",
        "df['PricePerTicket'] = temp_col\n",
        "\n",
        "# placing the two continuous variables in the beginning\n",
        "tickets_col = df.pop('NumTicketsOrdered')\n",
        "df.insert(0, 'NumTicketsOrdered', tickets_col)\n",
        "miles_col = df.pop('Miles')\n",
        "df.insert(0, 'Miles', miles_col)\n",
        "\n",
        "# normalizing Quarter, Miles, and NumTicketsOrdered variables================================================\n",
        "bool_norm = True\n",
        "norm_vars = ['Miles', 'NumTicketsOrdered']\n",
        "\n",
        "if bool_norm:\n",
        "  for col in norm_vars:\n",
        "    df[col] = df[col] / df[col].max()\n",
        "# ===========================================================================================================\n",
        "\n",
        "df"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Miles</th>\n",
              "      <th>NumTicketsOrdered</th>\n",
              "      <th>MktCoupons</th>\n",
              "      <th>Quarter</th>\n",
              "      <th>Origin</th>\n",
              "      <th>Dest</th>\n",
              "      <th>ContiguousUSA</th>\n",
              "      <th>AirlineCompany</th>\n",
              "      <th>PricePerTicket</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.471443</td>\n",
              "      <td>0.05</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>PHL</td>\n",
              "      <td>LAX</td>\n",
              "      <td>2</td>\n",
              "      <td>AA</td>\n",
              "      <td>672.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.471443</td>\n",
              "      <td>0.05</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>PHL</td>\n",
              "      <td>LAX</td>\n",
              "      <td>2</td>\n",
              "      <td>AA</td>\n",
              "      <td>367.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.471443</td>\n",
              "      <td>0.05</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>PHL</td>\n",
              "      <td>LAX</td>\n",
              "      <td>2</td>\n",
              "      <td>AA</td>\n",
              "      <td>417.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.471443</td>\n",
              "      <td>0.05</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>PHL</td>\n",
              "      <td>LAX</td>\n",
              "      <td>2</td>\n",
              "      <td>AA</td>\n",
              "      <td>247.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.471443</td>\n",
              "      <td>0.05</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>PHL</td>\n",
              "      <td>LAX</td>\n",
              "      <td>2</td>\n",
              "      <td>AA</td>\n",
              "      <td>276.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9534412</th>\n",
              "      <td>0.141511</td>\n",
              "      <td>0.05</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>STL</td>\n",
              "      <td>AUS</td>\n",
              "      <td>2</td>\n",
              "      <td>WN</td>\n",
              "      <td>310.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9534413</th>\n",
              "      <td>0.096369</td>\n",
              "      <td>0.05</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>BNA</td>\n",
              "      <td>MCI</td>\n",
              "      <td>2</td>\n",
              "      <td>WN</td>\n",
              "      <td>106.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9534414</th>\n",
              "      <td>0.247301</td>\n",
              "      <td>0.05</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>BOS</td>\n",
              "      <td>LIT</td>\n",
              "      <td>2</td>\n",
              "      <td>WN</td>\n",
              "      <td>161.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9534415</th>\n",
              "      <td>0.247301</td>\n",
              "      <td>0.05</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>BOS</td>\n",
              "      <td>LIT</td>\n",
              "      <td>2</td>\n",
              "      <td>WN</td>\n",
              "      <td>170.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9534416</th>\n",
              "      <td>0.247301</td>\n",
              "      <td>0.05</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>BOS</td>\n",
              "      <td>LIT</td>\n",
              "      <td>2</td>\n",
              "      <td>WN</td>\n",
              "      <td>379.02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9534417 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Miles  NumTicketsOrdered  ...  AirlineCompany  PricePerTicket\n",
              "0        0.471443               0.05  ...              AA          672.87\n",
              "1        0.471443               0.05  ...              AA          367.68\n",
              "2        0.471443               0.05  ...              AA          417.94\n",
              "3        0.471443               0.05  ...              AA          247.10\n",
              "4        0.471443               0.05  ...              AA          276.35\n",
              "...           ...                ...  ...             ...             ...\n",
              "9534412  0.141511               0.05  ...              WN          310.10\n",
              "9534413  0.096369               0.05  ...              WN          106.17\n",
              "9534414  0.247301               0.05  ...              WN          161.19\n",
              "9534415  0.247301               0.05  ...              WN          170.87\n",
              "9534416  0.247301               0.05  ...              WN          379.02\n",
              "\n",
              "[9534417 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fP1e1O4MQdjZ",
        "colab_type": "text"
      },
      "source": [
        "## First we separate the X and Y into training and testing datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRzfBKv4Qb5T",
        "colab_type": "code",
        "outputId": "ac5af7e3-8c89-4770-b9d9-d25ef074fe47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "\"\"\"\n",
        "shuffling the data before separating into X and Y\n",
        "configuring training and testing datasets\n",
        "\"\"\"\n",
        "\n",
        "data = df.to_numpy()\n",
        "\n",
        "print(f\"The shape of the data is: {data.shape}\")\n",
        "\n",
        "train, test = train_test_split(data, test_size=0.1, shuffle=True)\n",
        "\n",
        "X_train, Y_train = train[::1, :-1], train[::1, -1]\n",
        "X_test, Y_test = test[::1, :-1], test[::1, -1]\n",
        "\n",
        "print(f\"\\nTraining shape: {X_train.shape}\")\n",
        "print(f\"\\nTesting shape: {X_test.shape}\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of the data is: (9534417, 9)\n",
            "\n",
            "Training shape: (8580975, 8)\n",
            "\n",
            "Testing shape: (953442, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDtTr2Sm_4p2",
        "colab_type": "code",
        "outputId": "41412fac-6665-42b5-a319-d47fc816f28f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "\"\"\"\n",
        "preparing the inputs to the model by parsing the X_train, X_test variables\n",
        "this implementation is coming from an article\n",
        "EMBEDDING LAYERS FOR ALL 6 CATEGORICAL VARIABLES\n",
        "\"\"\"\n",
        "\n",
        "def parse_vars(var_data):\n",
        "\n",
        "  temp_cont = var_data[:, 0:2]\n",
        "\n",
        "  def categorical_func(cate_data):  \n",
        "      temp = list()\n",
        "      for i in range(cate_data.shape[1]):\n",
        "          le = LabelEncoder()\n",
        "          le.fit(cate_data[:, i])\n",
        "          label_encoded_feature = le.transform(cate_data[:, i])\n",
        "          temp.append(label_encoded_feature)\n",
        "      return temp\n",
        "\n",
        "  temp_cate = categorical_func(var_data[:, 2:])\n",
        "\n",
        "  return (temp_cont, temp_cate)\n",
        "\n",
        "train_continuous, train_categorical = parse_vars(X_train)\n",
        "test_continuous, test_categorical = parse_vars(X_test)\n",
        "\n",
        "print(f\"train_continuous.shape: {train_continuous.shape}\")\n",
        "print(f\"\\ntest_continuous.shape: {test_continuous.shape}\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_continuous.shape: (8580975, 2)\n",
            "\n",
            "test_continuous.shape: (953442, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMJEml7VqgkB",
        "colab_type": "text"
      },
      "source": [
        "## Now we will start making the dense neural network for the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxGTS62pRG8F",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Initiating loss for training and validation, creating callback functions for stopping training and saving the model periodically.\n",
        "\"\"\"\n",
        "keras callback\n",
        "\"\"\"\n",
        "\n",
        "# loss lists so that training need not be completed to plot graphs\n",
        "training_mse = []\n",
        "validation_mse = []\n",
        "\n",
        "class callback(Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if logs.get('mse') <= 0.01:\n",
        "      print(f'\\nTraining halted here. Model has achieved {round(logs.get(\"mse\"), 2)} loss on training set.')\n",
        "      self.model.stop_training = True\n",
        "    \n",
        "    training_mse.append(logs.get('mse'))\n",
        "    validation_mse.append(logs.get('val_mse'))\n",
        "\n",
        "call = ModelCheckpoint(checkpoint_dir, monitor='mse', verbose=1,\n",
        "    save_best_only=True, mode='auto', save_freq='epoch')\n",
        "\n",
        "training_stop = callback()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffqOH_GJkHBt",
        "colab_type": "code",
        "outputId": "da0d7da3-6efb-499b-da55-449379c2c8df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\"\"\"\n",
        "creating the keras model\n",
        "\"\"\"\n",
        "\n",
        "cont_input = Input(shape=(train_continuous.shape[-1],), name='continuous_input')\n",
        "cont = BatchNormalization(name='continuous_batchnorm')(cont_input)\n",
        "# ========================================================================================================\n",
        "continuous_dense = False\n",
        "if continuous_dense:\n",
        "  cont = Dense(units=7, activation='relu', name='dense_cont_1')(cont_input)\n",
        "\n",
        "  for i, unit in enumerate([], start=2):\n",
        "      cont = Dense(units=unit, activation='relu', name=f'dense_cont_{i}')(cont)\n",
        "# ========================================================================================================\n",
        "in_layers = list()\n",
        "em_layers = list()\n",
        "for i in range(len(train_categorical)):\n",
        "    n_labels = len(np.unique(train_categorical[i])) # unique values in each categorical column\n",
        "    in_layer = Input(shape=(1,), name=f'categorical_layer_{i+1}')\n",
        "    emb_shape = min(50, (n_labels + 1) // 2)\n",
        "    em_layer = Embedding(n_labels+1, emb_shape, name=f'embedding_layer_{i+1}')(in_layer)\n",
        "    em_layer = Reshape(target_shape=(emb_shape,), name=f'categorical_reshape_layer_{i+1}')(em_layer)\n",
        "    em_layer = Dropout(rate=0.5, name=f'categorical_dropout_layer_{i+1}')(em_layer)\n",
        "    in_layers.append(in_layer) # categorical variables\n",
        "    em_layers.append(em_layer)\n",
        "\n",
        "cate = concatenate(inputs=em_layers, name='merge_categorical')\n",
        "# ========================================================================================================\n",
        "categorical_dense = False\n",
        "if categorical_dense:\n",
        "  cate = Dense(units=8, activation='relu', name='dense_cate_1')(cate)\n",
        "\n",
        "  for i, unit in enumerate([], start=2):\n",
        "      cate = Dense(units=unit, activation='relu', name=f'dense_cate_{i}')(cate)\n",
        "# ========================================================================================================\n",
        "merged = concatenate(inputs=[cont, cate], name='merge_all')\n",
        "\n",
        "for i, unit in enumerate([85, 85], start=1):\n",
        "    merged = Dense(units=unit, activation='relu', name=f'merged_dense_{i}')(merged)\n",
        "    merged = BatchNormalization(name=f'merged_batchnorm_{i}')(merged)\n",
        "    merged = Dropout(rate=0.5, name=f'merged_dropout_{i}')(merged)\n",
        "\n",
        "out = Dense(units=1, activation='linear', name='output_layer')(merged)\n",
        "\n",
        "# creating the Model\n",
        "\n",
        "model = Model(inputs=[cont_input, in_layers], outputs=out, name='FP_Model')\n",
        "\n",
        "# saving the model graph and seeing the architecture \n",
        "\n",
        "plot_model(model, show_shapes=True, to_file='/content/drive/My Drive/MIA/nn_graph.png')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"FP_Model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "categorical_layer_1 (InputLayer [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "categorical_layer_2 (InputLayer [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "categorical_layer_3 (InputLayer [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "categorical_layer_4 (InputLayer [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "categorical_layer_5 (InputLayer [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "categorical_layer_6 (InputLayer [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_layer_1 (Embedding)   (None, 1, 2)         8           categorical_layer_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "embedding_layer_2 (Embedding)   (None, 1, 2)         10          categorical_layer_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "embedding_layer_3 (Embedding)   (None, 1, 50)        13150       categorical_layer_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "embedding_layer_4 (Embedding)   (None, 1, 50)        13050       categorical_layer_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "embedding_layer_5 (Embedding)   (None, 1, 1)         3           categorical_layer_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "embedding_layer_6 (Embedding)   (None, 1, 6)         78          categorical_layer_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "categorical_reshape_layer_1 (Re (None, 2)            0           embedding_layer_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "categorical_reshape_layer_2 (Re (None, 2)            0           embedding_layer_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "categorical_reshape_layer_3 (Re (None, 50)           0           embedding_layer_3[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "categorical_reshape_layer_4 (Re (None, 50)           0           embedding_layer_4[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "categorical_reshape_layer_5 (Re (None, 1)            0           embedding_layer_5[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "categorical_reshape_layer_6 (Re (None, 6)            0           embedding_layer_6[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "continuous_input (InputLayer)   [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "categorical_dropout_layer_1 (Dr (None, 2)            0           categorical_reshape_layer_1[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "categorical_dropout_layer_2 (Dr (None, 2)            0           categorical_reshape_layer_2[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "categorical_dropout_layer_3 (Dr (None, 50)           0           categorical_reshape_layer_3[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "categorical_dropout_layer_4 (Dr (None, 50)           0           categorical_reshape_layer_4[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "categorical_dropout_layer_5 (Dr (None, 1)            0           categorical_reshape_layer_5[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "categorical_dropout_layer_6 (Dr (None, 6)            0           categorical_reshape_layer_6[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "continuous_batchnorm (BatchNorm (None, 2)            8           continuous_input[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "merge_categorical (Concatenate) (None, 111)          0           categorical_dropout_layer_1[0][0]\n",
            "                                                                 categorical_dropout_layer_2[0][0]\n",
            "                                                                 categorical_dropout_layer_3[0][0]\n",
            "                                                                 categorical_dropout_layer_4[0][0]\n",
            "                                                                 categorical_dropout_layer_5[0][0]\n",
            "                                                                 categorical_dropout_layer_6[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "merge_all (Concatenate)         (None, 113)          0           continuous_batchnorm[0][0]       \n",
            "                                                                 merge_categorical[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "merged_dense_1 (Dense)          (None, 85)           9690        merge_all[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "merged_batchnorm_1 (BatchNormal (None, 85)           340         merged_dense_1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "merged_dropout_1 (Dropout)      (None, 85)           0           merged_batchnorm_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "merged_dense_2 (Dense)          (None, 85)           7310        merged_dropout_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "merged_batchnorm_2 (BatchNormal (None, 85)           340         merged_dense_2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "merged_dropout_2 (Dropout)      (None, 85)           0           merged_batchnorm_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "output_layer (Dense)            (None, 1)            86          merged_dropout_2[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 44,073\n",
            "Trainable params: 43,729\n",
            "Non-trainable params: 344\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_dMTKuMy9BG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "7357b8ab-37bc-44be-a9e4-db09b28741e0"
      },
      "source": [
        "\"\"\"\n",
        "compiling and fitting\n",
        "\"\"\"\n",
        "\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='mse', metrics=['mse'])\n",
        "\n",
        "# model will begin training with previously trained weights\n",
        "try:\n",
        "    model.load_weights(checkpoint_dir)\n",
        "except:\n",
        "    print('Model architecture has been changed. No weights loaded\\n\\n')\n",
        "\n",
        "# consistency with data types; train_categorical is a list of np.ndarray\n",
        "train_continuous = np.asarray(train_continuous, dtype=np.float32)\n",
        "test_continuous = np.asarray(test_continuous, dtype=np.float32)\n",
        "Y_train = np.asarray(Y_train, dtype=np.float32)\n",
        "\n",
        "history = model.fit(\n",
        "    [train_continuous, train_categorical],\n",
        "    Y_train,\n",
        "    batch_size=512,\n",
        "    epochs=500,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[call, training_stop]\n",
        ")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model architecture has been changed. No weights loaded\n",
            "\n",
            "\n",
            "Epoch 1/500\n",
            " 6649/13408 [=============>................] - ETA: 49s - loss: 16271.9072 - mse: 16271.9072"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-03b37d359ab9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY7yKB1qxnCG",
        "colab_type": "code",
        "outputId": "4478ba59-6f5f-43f9-a7ea-023efd6bb587",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "source": [
        "\"\"\"\n",
        "plotting losses\n",
        "\"\"\"\n",
        "\n",
        "width_in_inches = 30\n",
        "height_in_inches = 10\n",
        "dots_per_inch = 50\n",
        "\n",
        "plt.figure(\n",
        "    figsize=(width_in_inches, height_in_inches),\n",
        "    dpi=dots_per_inch)\n",
        "\n",
        "plt.rcParams['axes.facecolor'] = '#3D383D'\n",
        "plt.rcParams['legend.facecolor'] = 'white'\n",
        "\n",
        "plt.plot(training_mse, 'o--b', label='training loss', mew=7, linewidth=3)\n",
        "plt.plot(validation_mse, 'o--r', label='validation loss', mew=7, linewidth=3)\n",
        "plt.legend(loc=\"upper right\", fontsize=25)\n",
        "\n",
        "plt.xlabel('Epoch', fontsize=38, color='white')\n",
        "plt.ylabel('MSE', fontsize=38, color='white')\n",
        "\n",
        "plt.xticks(range(1, len(training_mse)), fontsize=17, color='white')\n",
        "plt.yticks(fontsize=17, color='white')\n",
        "\n",
        "plt.grid(color='grey', linestyle=':', linewidth=1.7)\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1500x500 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "dark"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKFfFGPJJ7b4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "loading the best trained model (can jump directly here if training is not required)\n",
        "\"\"\"\n",
        "\n",
        "model = load_model(checkpoint_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20zIqXJcVPH1",
        "colab_type": "text"
      },
      "source": [
        "## Now that we have a trained model with its losses plotted, we can test it on example flights.\n",
        "\n",
        "---\n",
        "\n",
        "## In order to avoid having colab crash the runtime because the numpy arrays are in magnitudes of millions (the subtract function is the culprit), we will save the arrays using numpy format on drive, restart the runtime, and then retrieve them for the computation. This is because upon testing it is observed that the runtime is able to perform the computation on large arrays if that is the only computation run on it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjp20mejn1fj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "saving the required data onto drive for later use\n",
        "\"\"\"\n",
        "\n",
        "# these go here for model predicting purposes =======\n",
        "ex_train = [train_continuous, train_categorical]\n",
        "ex_test = [test_continuous, test_categorical]\n",
        "# ===================================================\n",
        "\n",
        "# consistency with data types\n",
        "train_continuous = np.asarray(train_continuous, dtype=np.float32)\n",
        "test_continuous = np.asarray(test_continuous, dtype=np.float32)\n",
        "# ======================================================================\n",
        "\n",
        "# saving model predictions on training and test sets\n",
        "preds_train = model.predict(ex_train, verbose=0)\n",
        "preds_test = model.predict(ex_test, verbose=0)\n",
        "\n",
        "save(model_preds_train, preds_train)\n",
        "save(model_preds_test, preds_test)\n",
        "\n",
        "# saving the true Y values\n",
        "save(truth_train, Y_train)\n",
        "save(truth_test, Y_test)\n",
        "\n",
        "# saving the continuous training and test variables\n",
        "save(train_continuous_dir, train_continuous)\n",
        "save(test_continuous_dir, test_continuous)\n",
        "\n",
        "# saving the categorical training and test variables\n",
        "save(train_categorical_dir, train_categorical)\n",
        "save(test_categorical_dir, test_categorical)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0KiryUXpJsd",
        "colab_type": "text"
      },
      "source": [
        "# RESTART RUNTIME HERE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "form",
        "id": "r8_AbKQeNfa0",
        "colab": {}
      },
      "source": [
        "#@title Require libraries import cell\n",
        "\"\"\"\n",
        "required libraries imported\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import print_function\n",
        "import os, io, sys, random, time, pprint\n",
        "import numpy as np\n",
        "from numpy import save, load\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import one_hot\n",
        "from tensorflow.keras.callbacks import LambdaCallback, Callback, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import Model, Sequential\n",
        "from tensorflow.keras import backend\n",
        "from tensorflow.keras.layers import Activation, Reshape, Dense, Embedding, Dropout, Input, LayerNormalization, BatchNormalization, concatenate, Flatten, Concatenate\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD, Adadelta, Adagrad, Adamax\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# SOME CONSTANTS\n",
        "checkpoint_dir = '/content/drive/My Drive/MIA/best_model.hdf5'\n",
        "model_preds_train = '/content/drive/My Drive/MIA/train_preds.npy'\n",
        "model_preds_test = '/content/drive/My Drive/MIA/test_preds.npy'\n",
        "truth_train = '/content/drive/My Drive/MIA/truth_train.npy'\n",
        "truth_test = '/content/drive/My Drive/MIA/truth_test.npy'\n",
        "train_continuous_dir = '/content/drive/My Drive/MIA/train_continuous_dir.npy'\n",
        "test_continuous_dir = '/content/drive/My Drive/MIA/test_continuous_dir.npy'\n",
        "train_categorical_dir = '/content/drive/My Drive/MIA/train_categorical_dir.npy'\n",
        "test_categorical_dir = '/content/drive/My Drive/MIA/test_categorical_dir.npy'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrzjQomWpVYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "loading the saved data from drive\n",
        "\"\"\"\n",
        "\n",
        "# loading model predictions on training and test sets\n",
        "preds_train = load(model_preds_train)\n",
        "preds_test = load(model_preds_test)\n",
        "\n",
        "# loading the true Y values\n",
        "Y_train = load(truth_train, allow_pickle=True)\n",
        "Y_test = load(truth_test, allow_pickle=True)\n",
        "\n",
        "# loading the continuous training and test variables\n",
        "train_continuous = load(train_continuous_dir)\n",
        "test_continuous = load(test_continuous_dir)\n",
        "\n",
        "# loading the categorical training and test variables\n",
        "train_categorical = load(train_categorical_dir)\n",
        "test_categorical = load(test_categorical_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEekkyDIoJDS",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title enlarge(feature) util function implemented\n",
        "\"\"\"\n",
        "important util function to modify the input model shapes\n",
        "\"\"\"\n",
        "\n",
        "def enlarge(feature):\n",
        "  \n",
        "  if len(feature.shape) == 0:\n",
        "    return enlarge(np.expand_dims(feature, 0))\n",
        "\n",
        "  return np.expand_dims(feature, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHTHwQq5ewKU",
        "colab_type": "code",
        "outputId": "a706a574-912b-4c98-eec7-75fcd648699e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "\"\"\"\n",
        "testing the model on an example flight price\n",
        "\"\"\"\n",
        "\n",
        "rand_train = random.randint(0, len(Y_train))\n",
        "rand_test = random.randint(0, len(Y_test))\n",
        "\n",
        "truths_train = round(float(Y_train[rand_train]), 2) \n",
        "truths_test = round(float(Y_test[rand_test]), 2)\n",
        "\n",
        "pred_train = round(float(preds_train[rand_train]), 2)\n",
        "pred_test = round(float(preds_test[rand_test]), 2)\n",
        "\n",
        "print(f\"A training example\\nTrue price: ${truths_train}, model predicted: ${pred_train}\")\n",
        "print(f\"\\n\\nA testing example\\nTrue price: ${truths_test}, model predicted: ${pred_test}\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A training example\n",
            "True price: $374.0, model predicted: $255.42\n",
            "\n",
            "\n",
            "A testing example\n",
            "True price: $103.0, model predicted: $232.89\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZV0C6VGW5ft",
        "colab_type": "text"
      },
      "source": [
        "## Checking the model's accuracy on the training and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gpk-ETdZfqI",
        "colab_type": "code",
        "outputId": "ebc5d9e0-9b3e-4ea0-da1b-bcb820cb2f7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "\"\"\"\n",
        "predicting an approximate accuracy of the model\n",
        "if the model predicts the correct price of a flight with a +- epsilon value\n",
        "then that will be a correct prediction, else incorrect\n",
        "\"\"\"\n",
        "\n",
        "epsilon = 70.0\n",
        "\n",
        "def accuracy(spec='train'):\n",
        "  preds = None\n",
        "  if spec == 'train':\n",
        "    preds = np.squeeze(preds_train)\n",
        "    diff = np.absolute(np.subtract(preds, Y_train))\n",
        "    diff = diff <= epsilon\n",
        "    diff = diff.astype(int)\n",
        "    diff = diff.sum()\n",
        "    return round((float(diff) / Y_train.shape[0]) * 100, 2)\n",
        "\n",
        "  else:\n",
        "    preds = np.squeeze(preds_test)\n",
        "    diff = np.absolute(np.subtract(preds, Y_test))\n",
        "    diff = diff <= epsilon\n",
        "    diff = diff.astype(int)\n",
        "    diff = diff.sum()\n",
        "    return round((float(diff) / Y_test.shape[0]) * 100, 2)\n",
        "\n",
        "print(f\"Epsilon taken as ${int(epsilon)}\")\n",
        "print(f\"Accuracy on the training set: {accuracy('train')}%\")\n",
        "print(f\"Accuracy on the test set: {accuracy('test')}%\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epsilon taken as $70\n",
            "Accuracy on the training set: 44.12%\n",
            "Accuracy on the test set: 44.14%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZPkQdeeVdPs",
        "colab_type": "text"
      },
      "source": [
        "## Once the model is satisfiably good, it will be exported as a tf model to the drive to be uploaded to [mia](http://miamarketplace.com/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8LfhIpIG-Sz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "saving the model and the files for uploading to mia\n",
        "checking the tensorflow and python versions\n",
        "\"\"\"\n",
        "\n",
        "model.save('/content/drive/My Drive/MIA/', save_format='tf')\n",
        "\n",
        "print(tf.__version__)\n",
        "! python --version"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}